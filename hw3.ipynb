{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCIS6273 Data Mining (Prof. Maull) / Fall 2020 / HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Name: \n",
    "### SAU ID    : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBJECTIVES\n",
    "* Perform Bayesian text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSIGNMENT TASKS\n",
    "### (100%) Perform Bayesian text classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with the documents we want to load, you will want to study \n",
    "\n",
    "* [`from sklearn.feature_extraction.text import TfidfVectorizer`]()\n",
    "* [`from sklearn.naive_bayes import MultinomialNB`]()\n",
    "\n",
    "Our test data will be given by the following dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "training_map = {\n",
    "    'a': \n",
    "        [ # Plato\n",
    "        'data/plato/train/pg1750.txt', # Laws\n",
    "        'data/plato/train/pg1497.txt', # The Republic\n",
    "        'data/plato/train/pg1600.txt', # Symposium\n",
    "        ],\n",
    "    'b':\n",
    "        [ # Hume\n",
    "        'data/hume/train/pg10574.txt', # The History of England, Volume I\n",
    "        'data/hume/train/pg4705.txt',  # A Treatise of Human Nature\n",
    "        'data/hume/train/pg36120.txt', # Essays\n",
    "        ],\n",
    "    'c':\n",
    "        [ # Aristotle\n",
    "        'data/aristotle/train/pg8438.txt', # Ethics\n",
    "        'data/aristotle/train/pg26095.txt',# The Athenian Constitution\n",
    "        'data/aristotle/train/pg6763.txt'  # The Poetics\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for k in training_map.keys():\n",
    "    X_train.extend(training_map[k])\n",
    "    y_train.extend(k * len(training_map[k]))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/plato/train/pg1750.txt',\n",
       " 'data/plato/train/pg1497.txt',\n",
       " 'data/plato/train/pg1600.txt',\n",
       " 'data/hume/train/pg10574.txt',\n",
       " 'data/hume/train/pg4705.txt',\n",
       " 'data/hume/train/pg36120.txt',\n",
       " 'data/aristotle/train/pg8438.txt',\n",
       " 'data/aristotle/train/pg26095.txt',\n",
       " 'data/aristotle/train/pg6763.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_map = {\n",
    "    'a': # Plato\n",
    "        [\n",
    "        'data/plato/test/pg1726.txt', # Title: Cratylus\n",
    "        'data/plato/test/pg1616.txt', # Title: Ion\n",
    "        'data/plato/test/pg1735.txt', # Title: Theaetetus \n",
    "        'data/plato/test/pg1635.txt'  # Title: Sophist\n",
    "        ],\n",
    "    'b': \n",
    "        [ # Hume\n",
    "        'data/hume/test/pg59792-0.txt', # Title: Hume's Political Discourses\n",
    "        'data/hume/test/pg62856-0.txt', # Title: A Treatise of Human Nature Being an Attempt to Introduce the Experimental Method into Moral Subjects\n",
    "        'data/hume/test/pg9662.txt',    # Title: An Enquiry Concerning Human Understanding\n",
    "        ],\n",
    "    'c':\n",
    "        [ # Aristotle\n",
    "        'data/aristotle/test/pg59058.txt', # Title: Aristotle's History of Animals In Ten Books\n",
    "        'data/aristotle/test/pg2412.txt',  # Title: The Categories\n",
    "        'data/aristotle/test/pg6762.txt',  # Title: Politics A Treatise on Government\n",
    "        'data/aristotle/test/pg1974.txt',  # Title: Poetics\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for k in testing_map.keys():\n",
    "    X_test.extend(testing_map[k])\n",
    "    y_test.extend(k * len(testing_map[k]))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/plato/test/pg1726.txt',\n",
       " 'data/plato/test/pg1616.txt',\n",
       " 'data/plato/test/pg1735.txt',\n",
       " 'data/plato/test/pg1635.txt',\n",
       " 'data/hume/test/pg59792-0.txt',\n",
       " 'data/hume/test/pg62856-0.txt',\n",
       " 'data/hume/test/pg9662.txt',\n",
       " 'data/aristotle/test/pg59058.txt',\n",
       " 'data/aristotle/test/pg2412.txt',\n",
       " 'data/aristotle/test/pg6762.txt',\n",
       " 'data/aristotle/test/pg1974.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'a', 'a', 'a', 'b', 'b', 'b', 'c', 'c', 'c', 'c']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the dictionary map in the variable\n",
    "          `training_map`. Your function will take the files (in the order they appear in\n",
    "          `training_map`) and pass the  data into the [`TfidfVectorizer`]() vectorizer.  You\n",
    "          will need to set the parameter to the constructor to `input='file'` and the\n",
    "          `stop_words` to `'english'` (e.g. initialize the vectorizer to `TfidfVectorizer(input='file', stop_words='english')`.\n",
    "\n",
    "* **You will just need to show the new function and the initialization of the vectorizer in this step.**  This will be one or two cells at most.\n",
    "* You will use `fit_transform()` with the parameter being a list of the training files objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVectorsInfo(tfidfVectorizer,X_train):\n",
    "    return tfidfVectorizer.fit_transform([open(file, 'r', encoding='utf-8') for file in X_train]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfVectorizer = TfidfVectorizer(input='file', stop_words='english')\n",
    "tfidfVectorizerVectors = getVectorsInfo(tfidfVectorizer,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tfidfVectorizerVectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfVectorizerVectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 24856)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfVectorizerVectors.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART II\n",
    "\n",
    "Now that you have a vectorizer which effectively builds the data structure to hold the\n",
    "TF-IDF of all the words which appear for each document, you can move to the training\n",
    "phase for the Bayesian classifier.  Look in the sample notebook for guidance. You will take as\n",
    "input the vectorizer output (the documents vectorized by TF-IDF) and the corresponding\n",
    "classes (in the order they appear in the original dictionary map) and pass that into the [`MultinomialNB.fit()`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.fit) method.\n",
    "\n",
    "* **Show the initialization of your `MultinomialNB()` classifier and the application of the `fit()` method.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Initialize MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(tfidfVectorizerVectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 24856)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfVectorizerVectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.33333333333333"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(tfidfVectorizerVectors,y_train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART III\n",
    "\n",
    "Once you have the classifier, you will need to convert a test file using\n",
    "the vectorizer from part I.  Then you will execute the `predict()` \n",
    "method of your classifier.\n",
    "\n",
    "Assume `vectorizer` is your TF-IDF vectorizer from above and the `clf` your\n",
    "classifier from part II above, your code could be modeled after this:\n",
    "\n",
    "```python\n",
    "x_test = vectorizer.transform([open(\"data/aristotle/test/pg2412.txt\")])\n",
    "\n",
    "# should be class C!\n",
    "clf.predict(x_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your notebook do the following:\n",
    "\n",
    "1. **Write a function to take as input a vectorized document and trained classifier and return\n",
    "the predicted label for the document.**  See the sample notebook for guidance.\n",
    "\n",
    "1. **Test on the files in the `data/philosopher_name/test` folders and show the output of your test.**\n",
    "You can wrap your function from the previous step in a loop\n",
    "to run through all data in the folder.  This will be short enough to be coded in a single Jupyter cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_test = [\n",
    "    ('data/plato/test/pg1726.txt','a') ,\n",
    "    ('data/plato/test/pg1616.txt','a'),\n",
    "    ('data/plato/test/pg1735.txt','a'),\n",
    "    ('data/plato/test/pg1635.txt','a'),\n",
    "    ('data/hume/test/pg59792-0.txt','b'),\n",
    "    ('data/hume/test/pg62856-0.txt','b'),\n",
    "    ('data/hume/test/pg9662.txt','b'),\n",
    "    ('data/aristotle/test/pg59058.txt','c'),\n",
    "    ('data/aristotle/test/pg2412.txt','c'),\n",
    "    ('data/aristotle/test/pg6762.txt','c'),\n",
    "    ('data/aristotle/test/pg1974.txt','c')\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResultsForPredict(mnb,x_test):\n",
    "    return mnb.predict(x_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/plato/test/pg1726.txt: True\n",
      "data/plato/test/pg1616.txt: True\n",
      "data/plato/test/pg1735.txt: True\n",
      "data/plato/test/pg1635.txt: True\n",
      "data/hume/test/pg59792-0.txt: False\n",
      "data/hume/test/pg62856-0.txt: False\n",
      "data/hume/test/pg9662.txt: False\n",
      "data/aristotle/test/pg59058.txt: False\n",
      "data/aristotle/test/pg2412.txt: False\n",
      "data/aristotle/test/pg6762.txt: False\n",
      "data/aristotle/test/pg1974.txt: False\n"
     ]
    }
   ],
   "source": [
    "for f, cls_predict in files_test:\n",
    "    # Load the file data into x_test\n",
    "    x_test = tfidfVectorizer.transform([open(f,'r', encoding='utf-8')])\n",
    "    pred = getResultsForPredict(mnb,x_test)\n",
    "    print (f\"{f}: {cls_predict == pred}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## &#167;  You have now built your first document classifier! \n",
    "## Now answer the following questions:\n",
    "\n",
    "#### 1. How many of the documents did your classifier correctly classify?\n",
    "### Ans:\n",
    "Four documents are correctly classifying on MultinomialNB.The classifier `predict` method only returns the label.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As follow the classes labels from the classes_ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Labels:  ['a' 'b' 'c']\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes Labels: \",mnb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILE NAME                  : Predict_proba values\n",
      "================           : ====================\n",
      "data/plato/test/pg1726.txt => [[0.33333333 0.33333333 0.33333333]]\n",
      "data/plato/test/pg1616.txt => [[0.33333333 0.33333333 0.33333333]]\n",
      "data/plato/test/pg1735.txt => [[0.33333333 0.33333333 0.33333333]]\n",
      "data/plato/test/pg1635.txt => [[0.33333333 0.33333333 0.33333333]]\n",
      "data/hume/test/pg59792-0.txt => [[0.33333333 0.33333333 0.33333333]]\n",
      "data/hume/test/pg62856-0.txt => [[0.33333333 0.33333333 0.33333333]]\n",
      "data/hume/test/pg9662.txt => [[0.33333333 0.33333333 0.33333333]]\n",
      "data/aristotle/test/pg59058.txt => [[0.33333333 0.33333333 0.33333333]]\n",
      "data/aristotle/test/pg2412.txt => [[0.33333333 0.33333333 0.33333333]]\n",
      "data/aristotle/test/pg6762.txt => [[0.33333333 0.33333333 0.33333333]]\n",
      "data/aristotle/test/pg1974.txt => [[0.33333333 0.33333333 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "print(\"FILE NAME                  : Predict_proba values\")\n",
    "print(\"================           : ====================\")\n",
    "for file, cls_predict in files_test:\n",
    "    # Loading the test data files wiht transform method\n",
    "    x_test = tfidfVectorizer.transform([open(file,'r', encoding='utf-8')])\n",
    "    # finding predict_proba values\n",
    "    pred_proba = mnb.predict_proba(x_test)\n",
    "    print(file,\"=>\",pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Answer the following questions inside your notebook:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Make an observation about the class probabilities.  What did you notice?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "The X_train and class label output of model indicated to as y.Here X_train and y_train are taken from given data.\n",
    "The class probabilities are as follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes Labels:  ['a' 'b' 'c']\n",
      "Total number of classes as follow.\n",
      "====================================\n",
      "a\n",
      "a\n",
      "a\n",
      "b\n",
      "b\n",
      "b\n",
      "c\n",
      "c\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "#The P(train) is also called class probability.\n",
    "print(\"Classes Labels: \",mnb.classes_)\n",
    "print(\"Total number of classes as follow.\")\n",
    "print(\"====================================\")\n",
    "for f in y_train:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documnets as follow.\n",
      "====================================\n",
      "data/plato/train/pg1750.txt\n",
      "data/plato/train/pg1497.txt\n",
      "data/plato/train/pg1600.txt\n",
      "data/hume/train/pg10574.txt\n",
      "data/hume/train/pg4705.txt\n",
      "data/hume/train/pg36120.txt\n",
      "data/aristotle/train/pg8438.txt\n",
      "data/aristotle/train/pg26095.txt\n",
      "data/aristotle/train/pg6763.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of documnets as follow.\")\n",
    "print(\"====================================\")\n",
    "for f in X_train:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes Labels:  ['a' 'b' 'c']\n",
    "\n",
    "Let 'd' is the document file.\n",
    "\n",
    "In Plato  training set of 3 documents that we have pre-determined to belong to a specific class 'a'.\n",
    "In Hume  training set of 3 documents that we have pre-determined to belong to a specific class 'b'.\n",
    "In Aristotle  training set of 3 documents that we have pre-determined to belong to a specific class 'c'.\n",
    "\n",
    "Let y is the MultinomialNB() classifier. \n",
    "\n",
    "We train our classifier using the training set andthen  finally get the results on MultinomialNB() classifier.\n",
    "\n",
    "We have to applyed the classifier to ge the results y is classiffier to apply Y(d) = C.\n",
    "here c is class we assigned to the document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Provide some commentary on how the probabilities might be improved (you can provide you answer as a thought exercise or if you have time, provide some example code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ans:\n",
    "\n",
    "The probabilities are improved by the predict_prob() method for test vector X_test.\n",
    "The predict() method to predict the labels of data from trained data obtained wiht the help of classifier.\n",
    "\n",
    "As show bellow example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score (in %) :  90.8685968819599\n",
      "Testing Score (in %) :  92.88888888888889\n",
      "[8 8 8 0 2 3 9 6 6 5 8 5 7 1 9 7 1 5 6 0 4 9 6 6 9 2 7 1 9 9 6 3 8 7 2 7 7\n",
      " 6 7 9 9 7 9 7 0 8 6 1 3 0 9 2 7 7 7 6 1 4 4 7 4 3 5 4 0 9 7 6 4 4 2 3 1 9\n",
      " 4 2 2 2 9 4 8 3 9 9 4 5 8 0 7 0 9 4 9 6 7 5 3 5 3 3 3 2 4 7 7 2 6 1 9 0 5\n",
      " 1 5 8 5 0 2 0 9 8 8 7 3 5 2 5 0 8 9 3 7 6 5 8 8 8 2 1 4 4 6 5 4 0 6 0 5 7\n",
      " 9 2 5 0 0 4 9 8 0 2 3 3 6 9 9 0 1 6 1 2 4 6 3 2 1 3 0 3 0 8 5 6 2 4 9 4 6\n",
      " 7 8 9 7 7 9 5 5 6 0 4 5 4 1 5 3 3 3 6 0 6 3 3 8 3 5 8 8 6 5 8 4 6 7 3 2 3\n",
      " 1 0 7 5 5 7 5 1 4 9 1 7 3 9 8 7 5 6 9 1 4 1 4 9 9 0 9 0 6 8 7 9 4 2 4 6 3\n",
      " 3 0 9 3 5 9 7 0 6 8 1 5 0 5 1 9 2 9 2 1 0 5 9 4 8 9 2 9 2 9 7 7 0 7 6 1 5\n",
      " 0 2 6 6 0 6 2 2 1 3 5 7 9 9 8 7 4 1 3 7 8 0 1 0 4 3 2 8 0 2 9 9 7 9 5 7 9\n",
      " 8 6 1 4 2 2 2 5 9 3 7 0 1 2 4 8 6 3 8 7 5 3 0 9 1 6 6 3 9 7 1 9 5 8 1 4 1\n",
      " 9 7 8 9 5 3 0 2 1 9 8 5 8 0 8 9 9 4 6 8 9 8 3 6 6 5 5 9 5 0 0 4 6 6 8 2 6\n",
      " 7 1 6 3 5 5 8 8 6 4 3 3 3 2 2 5 6 0 7 8 2 8 2 4 8 6 2 5 6 6 7 9 4 9 7 7 1\n",
      " 9 6 4 9 7 2]\n",
      "\n",
      "Classes :  [0 1 2 3 4 5 6 7 8 9]\n",
      "\n",
      "[[5.41149240e-084 5.54996257e-022 4.24484424e-024 ... 1.40999861e-029\n",
      "  1.00000000e+000 8.62949707e-061]\n",
      " [1.02436127e-112 4.19783916e-014 1.65597993e-006 ... 9.06070394e-031\n",
      "  9.99998344e-001 2.44796994e-052]\n",
      " [7.40270065e-080 1.70448024e-002 8.52431580e-037 ... 9.36315272e-011\n",
      "  9.82955198e-001 2.64270776e-042]\n",
      " ...\n",
      " [5.61488034e-026 1.92101669e-066 9.36283775e-060 ... 2.13549680e-050\n",
      "  2.35306705e-040 1.00000000e+000]\n",
      " [2.00146808e-093 7.20313157e-033 1.25098343e-068 ... 1.00000000e+000\n",
      "  9.25023128e-030 1.49374602e-034]\n",
      " [4.48305749e-154 8.96611309e-055 1.00000000e+000 ... 3.78957399e-142\n",
      "  1.09230074e-034 7.09730294e-082]]\n",
      "[8 8 8 0 2 3 9 6 6 5 8 5 7 1 9 7 1 5 6 0 4 2 6 6 1 2 7 2 9 5 8 3 7 7 2 7 7\n",
      " 6 7 9 9 7 9 7 0 8 6 1 3 0 9 2 9 7 7 6 1 4 4 7 4 3 5 4 0 9 7 6 4 4 2 3 1 9\n",
      " 4 2 2 3 9 4 4 3 9 9 4 5 8 0 3 0 9 4 9 6 3 5 3 5 3 3 3 2 4 9 7 1 6 8 9 0 5\n",
      " 1 5 8 5 0 2 0 9 8 8 7 3 5 2 5 0 8 9 3 7 6 5 8 8 8 2 1 4 4 6 5 4 0 6 0 5 7\n",
      " 9 2 5 0 0 4 9 9 0 2 3 3 6 1 9 0 1 6 1 2 4 6 3 2 1 3 0 3 0 8 5 6 1 4 9 4 6\n",
      " 7 8 5 7 7 9 5 5 6 0 4 5 4 1 5 3 3 3 6 0 6 3 3 8 3 5 2 8 6 5 1 4 6 7 3 2 3\n",
      " 1 0 7 5 5 7 5 1 4 9 2 7 3 9 8 7 5 6 9 1 4 1 4 9 9 0 9 0 6 8 7 9 4 2 4 6 3\n",
      " 3 0 9 3 5 9 7 0 6 8 1 5 0 5 1 9 2 1 2 8 0 5 9 4 8 5 2 9 2 9 7 7 0 7 6 1 5\n",
      " 0 2 6 6 0 6 2 2 1 3 5 7 8 5 8 7 4 1 3 7 8 0 1 0 4 3 2 8 0 2 9 9 7 9 5 7 3\n",
      " 8 6 1 4 2 2 2 5 9 3 7 0 1 2 4 3 6 3 8 7 5 3 0 9 1 6 6 3 9 7 1 1 5 8 1 4 1\n",
      " 9 7 8 9 5 3 0 1 1 9 8 5 8 0 8 8 9 4 6 3 9 8 3 6 6 5 5 9 5 0 0 4 6 6 8 2 6\n",
      " 7 1 6 3 5 5 8 8 6 4 3 3 3 2 2 5 6 0 7 8 2 8 2 4 8 6 2 5 6 6 7 9 4 9 7 7 1\n",
      " 9 6 4 9 7 2]\n",
      "MultinomialNB Bayesian text classification model accuracy(in %): 92.88888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)\n",
    "\n",
    "\n",
    "# training the model on training set \n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "mnb = MultinomialNB()\n",
    "# Training Data\n",
    "mnb.fit(X_train, y_train)\n",
    "print(\"Training score (in %) : \",mnb.score(X_train, y_train)*100)\n",
    "# Testing Data\n",
    "mnb.fit(X_test, y_test)\n",
    "print(\"Testing Score (in %) : \",mnb.score(X_test, y_test)*100)\n",
    "\n",
    "# use the model to predict the labels of the test data\n",
    "predicted = mnb.predict(X_test)\n",
    "print(predicted)\n",
    "print()\n",
    "print(\"Classes : \",mnb.classes_)\n",
    "print()\n",
    "predictedProba = mnb.predict_proba(X_test)\n",
    "print(predictedProba)\n",
    "\n",
    "expected = y_test\n",
    "print(expected)\n",
    "# print(predicted == expected)\n",
    "# comparing actual response values (y_test) with predicted response values (y_pred) \n",
    "from sklearn import metrics \n",
    "print(\"Bayesian text classification model accuracy(in %):\", metrics.accuracy_score(predicted, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict output shows as  0,1 and 2 but predict_proba() for calculates probability value of y is 0 or 1.\n",
    "predict() depends on the actual class and predict_proba() is depends on class probabilities.\n",
    "It must used ROC curve and find the threshold a boundary probability value for graphical representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
